{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/highway92/machine_learning/blob/main/year_dream/do/vggnet16_augmentation_withL2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6c50f01a-72fd-4804-9f54-d77b52d3991f",
      "metadata": {
        "id": "6c50f01a-72fd-4804-9f54-d77b52d3991f"
      },
      "source": [
        "# [모의 캐글-의료] 흉부 CT 코로나 감염 여부 분류\n",
        "- 이미지 binary 분류 과제\n",
        "- 담당: 이녕민M"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f51ba7c1-0393-47ec-89d9-f6f97072773b",
      "metadata": {
        "id": "f51ba7c1-0393-47ec-89d9-f6f97072773b"
      },
      "source": [
        "## Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4325d39-6344-4116-b343-df51696905ec",
      "metadata": {
        "tags": [],
        "id": "e4325d39-6344-4116-b343-df51696905ec"
      },
      "outputs": [],
      "source": [
        "# !apt-get update && apt-get install -y python3-opencv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f475804-13db-484c-a348-f01580e80a1e",
      "metadata": {
        "tags": [],
        "id": "6f475804-13db-484c-a348-f01580e80a1e"
      },
      "outputs": [],
      "source": [
        "# !pip install sklearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f881e2f4-71e5-4483-b7b2-effe3f21e4be",
      "metadata": {
        "id": "f881e2f4-71e5-4483-b7b2-effe3f21e4be"
      },
      "outputs": [],
      "source": [
        "# !pip install opencv-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "535b9c29-ba67-40fa-a5be-9a53911db25f",
      "metadata": {
        "id": "535b9c29-ba67-40fa-a5be-9a53911db25f"
      },
      "outputs": [],
      "source": [
        "# !pip install pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "08f1be3d-5652-42ba-be7b-08c9c4bbff32",
      "metadata": {
        "id": "08f1be3d-5652-42ba-be7b-08c9c4bbff32"
      },
      "outputs": [],
      "source": [
        "# !pip install wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "98a45c7e-10ca-4fd1-9fd4-6326313a631a",
      "metadata": {
        "id": "98a45c7e-10ca-4fd1-9fd4-6326313a631a"
      },
      "outputs": [],
      "source": [
        "import os, torch, copy, cv2, sys, random\n",
        "# from datetime import datetime, timezone, timedelta\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torchvision.transforms as transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f754d77-3881-4bba-9e2e-3670f36744a9",
      "metadata": {
        "id": "9f754d77-3881-4bba-9e2e-3670f36744a9"
      },
      "outputs": [],
      "source": [
        "# wandb.init(project = 'test-project', entity = 'pnm-team')\n",
        "# wandb.log({\"loss\": 1})\n",
        "# wandb.finish()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a6c255b-b30d-4ffd-a663-bc01a2c37954",
      "metadata": {
        "id": "3a6c255b-b30d-4ffd-a663-bc01a2c37954"
      },
      "source": [
        "## Set Arguments & hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f9c4250-2257-404f-941d-58eff1e9eb38",
      "metadata": {
        "id": "8f9c4250-2257-404f-941d-58eff1e9eb38"
      },
      "outputs": [],
      "source": [
        "# 시드(seed) 설정\n",
        "\n",
        "RANDOM_SEED = 2022\n",
        "\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "np.random.seed(RANDOM_SEED)\n",
        "random.seed(RANDOM_SEED)"
      ]
    },
    {
      "cell_type": "raw",
      "id": "a9c63836-0a7a-48f7-a5ea-e16b617fec65",
      "metadata": {
        "id": "a9c63836-0a7a-48f7-a5ea-e16b617fec65"
      },
      "source": [
        "# 데이터 디렉토리 구조\n",
        "\n",
        "data/  \n",
        "  \\_train/  \n",
        "    \\_0.png  \n",
        "    \\_1.png  \n",
        "    \\_...  \n",
        "  \\_test/  \n",
        "    \\_0.png  \n",
        "    \\_1.png  \n",
        "    \\_...  \n",
        "  \\_train.csv  \n",
        "  \\_sample_submission.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d69a8bc-2e64-4de6-928f-4e16957f6af9",
      "metadata": {
        "id": "9d69a8bc-2e64-4de6-928f-4e16957f6af9",
        "outputId": "09c00c2f-15a7-49ed-88bf-ffe11635bdba"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# parameters\n",
        "\n",
        "### 데이터 디렉토리 설정 ###\n",
        "DATA_DIR= 'data'\n",
        "NUM_CLS = 2\n",
        "\n",
        "EPOCHS = 50\n",
        "BATCH_SIZE = 32\n",
        "LEARNING_RATE = 0.0005\n",
        "EARLY_STOPPING_PATIENCE = 10\n",
        "INPUT_SHAPE = 128\n",
        "\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "DEVICE"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d44807b0-7788-49ec-aff2-c756e4513c5e",
      "metadata": {
        "id": "d44807b0-7788-49ec-aff2-c756e4513c5e"
      },
      "source": [
        "## Dataloader"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a5b81fa5-3756-46aa-b3cb-6f19879aba05",
      "metadata": {
        "id": "a5b81fa5-3756-46aa-b3cb-6f19879aba05"
      },
      "source": [
        "#### Train & Validation Set loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "04642777-c2e0-439b-9692-f6c571a86521",
      "metadata": {
        "id": "04642777-c2e0-439b-9692-f6c571a86521"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, data_dir, mode, input_shape,aug_mode):\n",
        "        self.data_dir = data_dir\n",
        "        self.mode = mode\n",
        "        self.input_shape = input_shape\n",
        "        self.aug_mode = aug_mode\n",
        "        \n",
        "        # Loading dataset\n",
        "        self.db = self.data_loader()\n",
        "        \n",
        "        # Dataset split\n",
        "        if self.mode == 'train':\n",
        "            self.db = self.db[:int(len(self.db) * 0.9)]\n",
        "        elif self.mode == 'val':\n",
        "            self.db = self.db[int(len(self.db) * 0.9):]\n",
        "            self.db.reset_index(inplace=True)\n",
        "        else:\n",
        "            print(f'!!! Invalid split {self.mode}... !!!')\n",
        "            \n",
        "        # Transform function\n",
        "        if self.aug_mode == \"normal\":\n",
        "            self.transform = transforms.Compose([\n",
        "                                                 transforms.Resize(self.input_shape),\n",
        "                                                 transforms.ToTensor(),\n",
        "                                                 transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "        elif self.aug_mode == \"radom_crop\":\n",
        "            self.transform = transforms.Compose([\n",
        "                                                 transforms.RandomCrop(self.input_shape),\n",
        "                                                 transforms.ToTensor(),\n",
        "                                                 transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "        elif self.aug_mode == 'H_flip':\n",
        "            self.transform = transforms.Compose([\n",
        "                                                 transforms.Resize(self.input_shape),\n",
        "                                                 transforms.RandomHorizontalFlip(),\n",
        "                                                 transforms.ToTensor(),\n",
        "                                                 transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "        elif self.aug_mode == 'V_flip':\n",
        "            self.transform = transforms.Compose([\n",
        "                                                 transforms.Resize(self.input_shape),\n",
        "                                                 transforms.RandomVerticalFlip(),\n",
        "                                                 transforms.ToTensor(),\n",
        "                                                 transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "        elif self.aug_mode == 'rotate':\n",
        "            self.transform = transforms.Compose([\n",
        "                                                 transforms.Resize(self.input_shape),\n",
        "                                                 transforms.RandomRotation([-180, 180]),\n",
        "                                                 transforms.ToTensor(),\n",
        "                                                 transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "\n",
        "    def data_loader(self):\n",
        "        print('Loading ' + self.mode + ' dataset..')\n",
        "        if not os.path.isdir(self.data_dir):\n",
        "            print(f'!!! Cannot find {self.data_dir}... !!!')\n",
        "            sys.exit()\n",
        "        \n",
        "        # (COVID : 1, No : 0)\n",
        "        db = pd.read_csv(os.path.join(self.data_dir, 'train.csv'))\n",
        "        \n",
        "        return db\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.db)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        data = copy.deepcopy(self.db.loc[index])\n",
        "\n",
        "        # Loading image\n",
        "        cvimg = cv2.imread(os.path.join(self.data_dir,'train',data['file_name']), cv2.IMREAD_COLOR | cv2.IMREAD_IGNORE_ORIENTATION)\n",
        "        if not isinstance(cvimg, np.ndarray):\n",
        "            raise IOError(\"Fail to read %s\" % data['file_name'])\n",
        "\n",
        "        # Preprocessing images\n",
        "        trans_image = self.transform(Image.fromarray(cvimg))\n",
        "\n",
        "        return trans_image, data['COVID']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "61b27520-c82c-4ec8-ae0b-119a79167f09",
      "metadata": {
        "id": "61b27520-c82c-4ec8-ae0b-119a79167f09"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "685e0b73-f323-40ea-b372-6c1d607618a9",
      "metadata": {
        "id": "685e0b73-f323-40ea-b372-6c1d607618a9"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "VGG_types = {\n",
        "    'VGG16': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M']\n",
        "}\n",
        "\n",
        "class VGGnet(nn.Module):\n",
        "    def __init__(self, model, in_channels=3, num_classes=2, init_weights=True):\n",
        "        super(VGGnet, self).__init__()\n",
        "        self.in_channels = in_channels\n",
        "        self.conv_layers = self.create_conv_laters(VGG_types[model])\n",
        "        \n",
        "        self.fcs = nn.Sequential(\n",
        "            nn.Linear(512*4*4, 2048),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(2048, 1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(512, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(128, num_classes)\n",
        "        )\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "        \n",
        "        if init_weights:\n",
        "            self._initialize_weights()\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.conv_layers(x)\n",
        "        x = x.view(-1, 512*4*4)\n",
        "        x = self.fcs(x)\n",
        "        output = self.softmax(x)\n",
        "        return output\n",
        "    \n",
        "    def _initialize_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out',\n",
        "                                       nonlinearity='relu')\n",
        "                if m.bias is not None:\n",
        "                    nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                nn.init.normal_(m.weight, 0, 0.01)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "    \n",
        "    def create_conv_laters(self, architecture):\n",
        "        layers = []\n",
        "        in_channels = self.in_channels\n",
        "        \n",
        "        for x in architecture:\n",
        "            if type(x) == int:\n",
        "                out_channels = x\n",
        "                \n",
        "                layers += [nn.Conv2d(in_channels=in_channels, out_channels=out_channels,\n",
        "                                    kernel_size=(3,3), stride=(1,1), padding=(1,1)),\n",
        "                          nn.BatchNorm2d(x),\n",
        "                          nn.ReLU()]\n",
        "                in_channels = x\n",
        "            \n",
        "            elif x == 'M':\n",
        "                layers += [nn.MaxPool2d(kernel_size=(2,2), stride=(2,2))]\n",
        "        \n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "# class custom_CNN(nn.Module):\n",
        "#     def __init__(self, num_classes):\n",
        "#         super(custom_CNN, self).__init__()\n",
        "#         self.conv1 = nn.Conv2d(in_channels=3, out_channels=8, kernel_size=5)\n",
        "#         self.pool = nn.MaxPool2d(kernel_size=2)\n",
        "#         self.conv2 = nn.Conv2d(in_channels=8, out_channels=25, kernel_size=5)\n",
        "        \n",
        "#         self.fc1 = nn.Linear(in_features=25*29*29, out_features=128)\n",
        "#         self.fc2 = nn.Linear(in_features=128, out_features=num_classes)\n",
        "#         self.softmax = nn.Softmax(dim=1)\n",
        "        \n",
        "#     def forward(self, x):\n",
        "#         x = self.pool(F.relu(self.conv1(x))) # (32, 3, 128, 128) -> (32, 8, 62, 62)\n",
        "#         x = self.pool(F.relu(self.conv2(x))) # (32, 8, 62, 62) -> (32, 25, 29, 29)\n",
        "        \n",
        "#         x = torch.flatten(x,1)\n",
        "#         x = F.relu(self.fc1(x))\n",
        "#         x = F.relu(self.fc2(x))\n",
        "        \n",
        "#         output = self.softmax(x)\n",
        "        \n",
        "#         return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d60e25b-32ce-4750-a6ea-f612ccdddfe1",
      "metadata": {
        "id": "6d60e25b-32ce-4750-a6ea-f612ccdddfe1"
      },
      "outputs": [],
      "source": [
        "# # x = torch.randn(3,3,225,225).to(DEVICE)\n",
        "# model = VGGnet('VGG16').to(DEVICE)\n",
        "# model(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1d056905-1f77-4579-a260-07bb1056f6db",
      "metadata": {
        "id": "1d056905-1f77-4579-a260-07bb1056f6db"
      },
      "source": [
        "## Utils\n",
        "### EarlyStopper by loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b4c3315-ebca-4e6b-a8f2-1281ccd0bb87",
      "metadata": {
        "id": "1b4c3315-ebca-4e6b-a8f2-1281ccd0bb87"
      },
      "outputs": [],
      "source": [
        "# class LossEarlyStopper():\n",
        "#     \"\"\"Early stopper\n",
        "    \n",
        "#     Attributes:\n",
        "#         patience (int): loss가 줄어들지 않아도 학습할 epoch 수\n",
        "#         patience_counter (int): loss 가 줄어들지 않을 때 마다 1씩 증가, 감소 시 0으로 리셋\n",
        "#         min_loss (float): 최소 loss\n",
        "#         stop (bool): True 일 때 학습 중단\n",
        "\n",
        "#     \"\"\"\n",
        "\n",
        "#     def __init__(self, patience: int)-> None:\n",
        "#         self.patience = patience\n",
        "\n",
        "#         self.patience_counter = 0\n",
        "#         self.min_loss = np.Inf\n",
        "#         self.stop = False\n",
        "#         self.save_model = False\n",
        "\n",
        "#     def check_early_stopping(self, loss: float)-> None:\n",
        "#         \"\"\"Early stopping 여부 판단\"\"\"  \n",
        "\n",
        "#         if self.min_loss == np.Inf:\n",
        "#             self.min_loss = loss\n",
        "#             return None\n",
        "\n",
        "#         elif loss > self.min_loss:\n",
        "#             self.patience_counter += 1\n",
        "#             msg = f\"Early stopping counter {self.patience_counter}/{self.patience}\"\n",
        "\n",
        "#             if self.patience_counter == self.patience:\n",
        "#                 self.stop = True\n",
        "                \n",
        "#         elif loss <= self.min_loss:\n",
        "#             self.patience_counter = 0\n",
        "#             self.save_model = True\n",
        "#             msg = f\"Validation loss decreased {self.min_loss} -> {loss}\"\n",
        "#             self.min_loss = loss\n",
        "        \n",
        "#         print(msg)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d97d04b7-dbf2-4ef2-b38d-62bb0c5f0b41",
      "metadata": {
        "id": "d97d04b7-dbf2-4ef2-b38d-62bb0c5f0b41"
      },
      "source": [
        "# Early Stoppper by acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f8d3478-79c9-461f-81b2-d94355e1be7f",
      "metadata": {
        "id": "5f8d3478-79c9-461f-81b2-d94355e1be7f"
      },
      "outputs": [],
      "source": [
        "class LossEarlyStopper():\n",
        "    \"\"\"Early stopper\n",
        "    \n",
        "    Attributes:\n",
        "        patience (int): loss가 줄어들지 않아도 학습할 epoch 수\n",
        "        patience_counter (int): loss 가 줄어들지 않을 때 마다 1씩 증가, 감소 시 0으로 리셋\n",
        "        min_loss (float): 최소 loss\n",
        "        stop (bool): True 일 때 학습 중단\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, patience: int)-> None:\n",
        "        self.patience = patience\n",
        "\n",
        "        self.patience_counter = 0\n",
        "        self.max_acc = -np.Inf\n",
        "        self.stop = False\n",
        "        self.save_model = False\n",
        "\n",
        "    def check_early_stopping(self, acc: float)-> None:\n",
        "        \"\"\"Early stopping 여부 판단\"\"\"  \n",
        "\n",
        "        if self.max_acc == -np.Inf:\n",
        "            self.max_acc = acc\n",
        "            return None\n",
        "\n",
        "        elif acc < self.max_acc:\n",
        "            self.patience_counter += 1\n",
        "            self.save_model = False\n",
        "            msg = f\"Early stopping counter {self.patience_counter}/{self.patience}\"\n",
        "\n",
        "            if self.patience_counter == self.patience:\n",
        "                self.stop = True\n",
        "                \n",
        "        elif acc >= self.max_acc:\n",
        "            self.patience_counter = 0\n",
        "            self.save_model = True\n",
        "            msg = f\"Validation acc increased {self.max_acc} -> {acc}\"\n",
        "            self.max_acc = acc\n",
        "        \n",
        "        print(msg)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1aaffd8d-b025-42c1-8dd8-69529487389e",
      "metadata": {
        "id": "1aaffd8d-b025-42c1-8dd8-69529487389e"
      },
      "source": [
        "### Trainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5faaac1b-64c3-4659-82de-d4309502f29a",
      "metadata": {
        "id": "5faaac1b-64c3-4659-82de-d4309502f29a"
      },
      "outputs": [],
      "source": [
        "class Trainer():\n",
        "    \"\"\" epoch에 대한 학습 및 검증 절차 정의\"\"\"\n",
        "    \n",
        "    def __init__(self, loss_fn, model, device, metric_fn, optimizer=None, scheduler=None):\n",
        "        \"\"\" 초기화\n",
        "        \"\"\"\n",
        "        self.loss_fn = loss_fn\n",
        "        self.model = model\n",
        "        self.device = device\n",
        "        self.optimizer = optimizer\n",
        "        self.scheduler = scheduler\n",
        "        self.metric_fn = metric_fn\n",
        "\n",
        "    def train_epoch(self, dataloader, epoch_index):\n",
        "        \"\"\" 한 epoch에서 수행되는 학습 절차\"\"\"\n",
        "        \n",
        "        self.model.train()\n",
        "        train_total_loss = 0\n",
        "        target_lst = []\n",
        "        pred_lst = []\n",
        "        prob_lst = []\n",
        "\n",
        "        for batch_index, (img, label) in enumerate(dataloader):\n",
        "            img = img.to(self.device)\n",
        "            label = label.to(self.device).float()\n",
        "            \n",
        "            pred = self.model(img)\n",
        "            \n",
        "            loss = self.loss_fn(pred[:,1], label)\n",
        "            self.optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "            self.scheduler.step()\n",
        "            \n",
        "            train_total_loss += loss.item()\n",
        "            prob_lst.extend(pred[:, 1].cpu().tolist())\n",
        "            target_lst.extend(label.cpu().tolist())\n",
        "            pred_lst.extend(pred.argmax(dim=1).cpu().tolist())\n",
        "        self.train_mean_loss = train_total_loss / batch_index\n",
        "        self.train_score, f1 = self.metric_fn(y_pred=pred_lst, y_answer=target_lst)\n",
        "        msg = f'Epoch {epoch_index}, Train loss: {self.train_mean_loss}, Acc: {self.train_score}, F1-Macro: {f1}'\n",
        "        print(msg)\n",
        "\n",
        "    def validate_epoch(self, dataloader, epoch_index):\n",
        "        \"\"\" 한 epoch에서 수행되는 검증 절차\n",
        "        \"\"\"\n",
        "        self.model.eval()\n",
        "        val_total_loss = 0\n",
        "        target_lst = []\n",
        "        pred_lst = []\n",
        "        prob_lst = []\n",
        "\n",
        "        for batch_index, (img, label) in enumerate(dataloader):\n",
        "            img = img.to(self.device)\n",
        "            label = label.to(self.device).float()\n",
        "            pred = self.model(img)\n",
        "            \n",
        "            loss = self.loss_fn(pred[:,1], label)\n",
        "            val_total_loss += loss.item()\n",
        "            prob_lst.extend(pred[:, 1].cpu().tolist())\n",
        "            target_lst.extend(label.cpu().tolist())\n",
        "            pred_lst.extend(pred.argmax(dim=1).cpu().tolist())\n",
        "        self.val_mean_loss = val_total_loss / batch_index\n",
        "        self.validation_score, f1 = self.metric_fn(y_pred=pred_lst, y_answer=target_lst)\n",
        "        msg = f'Epoch {epoch_index}, Val loss: {self.val_mean_loss}, Acc: {self.validation_score}, F1-Macro: {f1}'\n",
        "        print(msg)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e2aca506-d168-4c9f-8eca-5cdecb122961",
      "metadata": {
        "id": "e2aca506-d168-4c9f-8eca-5cdecb122961"
      },
      "source": [
        "### Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33678d90-a254-48d5-bf09-2a817eeafea3",
      "metadata": {
        "id": "33678d90-a254-48d5-bf09-2a817eeafea3"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "def get_metric_fn(y_pred, y_answer):\n",
        "    \"\"\" 성능을 반환하는 함수\"\"\"\n",
        "    \n",
        "    assert len(y_pred) == len(y_answer), 'The size of prediction and answer are not same.'\n",
        "    accuracy = accuracy_score(y_answer, y_pred)\n",
        "    f1 = f1_score(y_answer, y_pred, average='macro')\n",
        "    return accuracy, f1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d729c079-9d85-49ce-857f-320b0c56a3a8",
      "metadata": {
        "tags": [],
        "id": "d729c079-9d85-49ce-857f-320b0c56a3a8"
      },
      "source": [
        "## Train\n",
        "### 학습을 위한 객체 선언"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b19610a4-ad7c-44a0-80cd-9734b5015100",
      "metadata": {
        "tags": [],
        "id": "b19610a4-ad7c-44a0-80cd-9734b5015100"
      },
      "source": [
        "#### Load Dataset & Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7cea68f0-dfad-47ce-a8ca-00ea01988886",
      "metadata": {
        "id": "7cea68f0-dfad-47ce-a8ca-00ea01988886",
        "outputId": "087d4a0e-6afb-4424-db52-9263c5100cbf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading train dataset..\n",
            "Loading val dataset..\n",
            "Train set samples: 581 Val set samples: 65\n"
          ]
        }
      ],
      "source": [
        "# Load dataset & dataloader\n",
        "train_dataset = CustomDataset(data_dir=DATA_DIR, mode='train', input_shape=INPUT_SHAPE, aug_mode = 'normal')\n",
        "validation_dataset = CustomDataset(data_dir=DATA_DIR, mode='val', input_shape=INPUT_SHAPE, aug_mode = 'normal')\n",
        "print('Train set samples:',len(train_dataset),  'Val set samples:', len(validation_dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b2349983-6e4d-4a04-8d13-42c4840c8a19",
      "metadata": {
        "id": "b2349983-6e4d-4a04-8d13-42c4840c8a19",
        "outputId": "d946d02c-80ba-46da-9394-0aed8eb978ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading train dataset..\n",
            "Loading train dataset..\n",
            "Loading train dataset..\n",
            "Loading train dataset..\n",
            "Loading train dataset..\n",
            "Loading val dataset..\n",
            "Loading val dataset..\n",
            "Loading val dataset..\n",
            "Loading val dataset..\n",
            "Loading val dataset..\n"
          ]
        }
      ],
      "source": [
        "aug_modes = ['normal','radom_crop', 'H_flip', 'V_flip', 'rotate']\n",
        "all_datasets = []\n",
        "all_validsets = []\n",
        "for mode in aug_modes:\n",
        "    d_set = CustomDataset(data_dir=DATA_DIR, mode='train', input_shape=INPUT_SHAPE, aug_mode = mode)\n",
        "    all_datasets.append(d_set)\n",
        "\n",
        "for mode in aug_modes:\n",
        "    d_set = CustomDataset(data_dir=DATA_DIR, mode='val', input_shape=INPUT_SHAPE, aug_mode = mode)\n",
        "    all_validsets.append(d_set)\n",
        "    \n",
        "train_dataset = torch.utils.data.ConcatDataset(all_datasets)\n",
        "validation_dataset = torch.utils.data.ConcatDataset(all_validsets)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4379db8-934f-4826-b8b3-584adeb12b1e",
      "metadata": {
        "id": "b4379db8-934f-4826-b8b3-584adeb12b1e",
        "outputId": "73743db1-7322-4740-9e16-8d78fcd888f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train set samples: 2905 Val set samples: 325\n"
          ]
        }
      ],
      "source": [
        "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "validation_dataloader = DataLoader(validation_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "print('Train set samples:',len(train_dataset),  'Val set samples:', len(validation_dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81fcf508-d5d8-412d-92f2-417f2d7bda3f",
      "metadata": {
        "id": "81fcf508-d5d8-412d-92f2-417f2d7bda3f",
        "outputId": "1a8abffd-20a9-45ea-beae-7ba42f7a7c69"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([3, 128, 128])\n"
          ]
        }
      ],
      "source": [
        "img, _ = train_dataset[1]\n",
        "print(img.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3bb8dae0-8e32-4ac0-a585-858a7095d2a4",
      "metadata": {
        "id": "3bb8dae0-8e32-4ac0-a585-858a7095d2a4"
      },
      "source": [
        "#### Load model and other utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb4d52e1-752a-40d5-9b34-c06d3dbdd45a",
      "metadata": {
        "id": "cb4d52e1-752a-40d5-9b34-c06d3dbdd45a"
      },
      "outputs": [],
      "source": [
        "# Load Model\n",
        "model = VGGnet('VGG16', num_classes=NUM_CLS).to(DEVICE)\n",
        "\n",
        "# # Save Initial Model\n",
        "# torch.save(model.state_dict(), 'initial.pt')\n",
        "\n",
        "# Set optimizer, scheduler, loss function, metric function\n",
        "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-5)\n",
        "scheduler =  optim.lr_scheduler.OneCycleLR(optimizer=optimizer, pct_start=0.1, div_factor=1e5, max_lr=0.0001, epochs=EPOCHS, steps_per_epoch=len(train_dataloader))\n",
        "loss_fn = nn.BCELoss()\n",
        "metric_fn = get_metric_fn\n",
        "\n",
        "\n",
        "# Set trainer\n",
        "trainer = Trainer(loss_fn, model, DEVICE, metric_fn, optimizer, scheduler)\n",
        "\n",
        "# Set earlystopper\n",
        "early_stopper = LossEarlyStopper(patience=EARLY_STOPPING_PATIENCE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b881024-3921-4c2c-b9ec-e6b23c4f5ad2",
      "metadata": {
        "tags": [],
        "id": "9b881024-3921-4c2c-b9ec-e6b23c4f5ad2",
        "outputId": "c6a118c2-40d6-4ca1-da30-2bc58addc361"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "VGGnet(\n",
              "  (conv_layers): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (5): ReLU()\n",
              "    (6): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
              "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (9): ReLU()\n",
              "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (12): ReLU()\n",
              "    (13): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
              "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (16): ReLU()\n",
              "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (19): ReLU()\n",
              "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (22): ReLU()\n",
              "    (23): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
              "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (26): ReLU()\n",
              "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (29): ReLU()\n",
              "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (32): ReLU()\n",
              "    (33): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
              "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (36): ReLU()\n",
              "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (39): ReLU()\n",
              "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (42): ReLU()\n",
              "    (43): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (fcs): Sequential(\n",
              "    (0): Linear(in_features=8192, out_features=2048, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Dropout(p=0.5, inplace=False)\n",
              "    (3): Linear(in_features=2048, out_features=1024, bias=True)\n",
              "    (4): ReLU()\n",
              "    (5): Dropout(p=0.5, inplace=False)\n",
              "    (6): Linear(in_features=1024, out_features=512, bias=True)\n",
              "    (7): ReLU()\n",
              "    (8): Dropout(p=0.5, inplace=False)\n",
              "    (9): Linear(in_features=512, out_features=128, bias=True)\n",
              "    (10): ReLU()\n",
              "    (11): Dropout(p=0.5, inplace=False)\n",
              "    (12): Linear(in_features=128, out_features=2, bias=True)\n",
              "  )\n",
              "  (softmax): Softmax(dim=1)\n",
              ")"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d5aa8aef-b984-4133-b6b2-e1c85900f724",
      "metadata": {
        "id": "d5aa8aef-b984-4133-b6b2-e1c85900f724"
      },
      "source": [
        "### epoch 단위 학습 진행"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1fdd5d8c-e601-47ac-a943-7aa505be316a",
      "metadata": {
        "id": "1fdd5d8c-e601-47ac-a943-7aa505be316a"
      },
      "outputs": [],
      "source": [
        "import gc\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c2cf1a6-2e29-46f6-9630-8d2526e51d99",
      "metadata": {
        "id": "6c2cf1a6-2e29-46f6-9630-8d2526e51d99",
        "outputId": "93a30098-2a34-4911-c969-63275547eab0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mpnm\u001b[0m (use `wandb login --relogin` to force relogin)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "                    Syncing run <strong><a href=\"https://wandb.ai/pnm-team/week1_Image/runs/jxbrkc0x\" target=\"_blank\">VGG16_vaild_aug_L2</a></strong> to <a href=\"https://wandb.ai/pnm-team/week1_Image\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
              "\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/pnm-team/week1_Image/runs/jxbrkc0x?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7fc596575670>"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# DATA_DIR= 'data'\n",
        "# NUM_CLS = 2\n",
        "\n",
        "# EPOCHS = 30\n",
        "# BATCH_SIZE = 32\n",
        "# LEARNING_RATE = 0.0005\n",
        "# EARLY_STOPPING_PATIENCE = 10\n",
        "# INPUT_SHAPE = 128\n",
        "import wandb\n",
        "\n",
        "wandb.init(project = 'week1_Image', entity = 'pnm-team',name = \"VGG16_vaild_aug_L2\",group = 'VGG', config={\n",
        "    'lr' : LEARNING_RATE,\n",
        "    'epochs' : EPOCHS,\n",
        "    'batch_size' : BATCH_SIZE,\n",
        "    'input_shape' : INPUT_SHAPE\n",
        "})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dcc35f70-25fc-48e1-92f8-8633b3b8be80",
      "metadata": {
        "id": "dcc35f70-25fc-48e1-92f8-8633b3b8be80",
        "outputId": "7aa1960e-2ebf-4372-b486-b2999099fca9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0% 0/30 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0, Train loss: 0.70093744330936, Acc: 0.47986230636833044, F1-Macro: 0.45748415663227626\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  3% 1/30 [04:44<2:17:18, 284.08s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0, Val loss: 0.7624521911144256, Acc: 0.5169230769230769, F1-Macro: 0.3905352301095305\n",
            "Epoch 1, Train loss: 0.7004551397429573, Acc: 0.5487091222030981, F1-Macro: 0.528035119509463\n",
            "Epoch 1, Val loss: 0.7615539014339447, Acc: 0.5476923076923077, F1-Macro: 0.4706312535318951\n",
            "Validation acc increased 0.5169230769230769 -> 0.5476923076923077\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  7% 2/30 [10:12<2:18:43, 297.25s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2, Train loss: 0.6680682539939881, Acc: 0.6123924268502582, F1-Macro: 0.5782089609206643\n",
            "Epoch 2, Val loss: 0.6820093631744385, Acc: 0.6584615384615384, F1-Macro: 0.6574106608674182\n",
            "Validation acc increased 0.5476923076923077 -> 0.6584615384615384\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 10% 3/30 [16:16<2:22:48, 317.34s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3, Train loss: 0.5860300007793638, Acc: 0.7111876075731497, F1-Macro: 0.7090326836008966\n",
            "Epoch 3, Val loss: 0.6725789666175842, Acc: 0.6984615384615385, F1-Macro: 0.6815\n",
            "Validation acc increased 0.6584615384615384 -> 0.6984615384615385\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 13% 4/30 [22:23<2:24:01, 332.36s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4, Train loss: 0.5438664221101337, Acc: 0.7283993115318417, F1-Macro: 0.7282415188297542\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 17% 5/30 [28:16<2:21:01, 338.47s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4, Val loss: 1.049121904373169, Acc: 0.68, F1-Macro: 0.6783892821801019\n",
            "Early stopping counter 1/10\n",
            "Epoch 5, Train loss: 0.49044133557213676, Acc: 0.770051635111876, F1-Macro: 0.769194794864134\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 20% 6/30 [34:45<2:21:27, 353.65s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5, Val loss: 0.6324411630630493, Acc: 0.6923076923076923, F1-Macro: 0.692281472504166\n",
            "Early stopping counter 2/10\n",
            "Epoch 6, Train loss: 0.4586681243446138, Acc: 0.7759036144578313, F1-Macro: 0.7757878821326598\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 23% 7/30 [40:56<2:17:35, 358.92s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6, Val loss: 0.7061649903655052, Acc: 0.6215384615384615, F1-Macro: 0.6031273268801192\n",
            "Early stopping counter 3/10\n",
            "Epoch 7, Train loss: 0.44017411520083743, Acc: 0.7917383820998278, F1-Macro: 0.7913458493967043\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 27% 8/30 [47:12<2:13:27, 363.98s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7, Val loss: 0.7396586090326309, Acc: 0.6369230769230769, F1-Macro: 0.6359269385585176\n",
            "Early stopping counter 4/10\n",
            "Epoch 8, Train loss: 0.41484505467944677, Acc: 0.8103270223752151, F1-Macro: 0.8098199672667759\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 30% 9/30 [53:14<2:07:14, 363.54s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8, Val loss: 0.8802556991577148, Acc: 0.6676923076923077, F1-Macro: 0.6538461538461539\n",
            "Early stopping counter 5/10\n",
            "Epoch 9, Train loss: 0.3657419999440511, Acc: 0.8296041308089501, F1-Macro: 0.829207457753944\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 33% 10/30 [59:02<1:59:33, 358.70s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9, Val loss: 0.8579304784536361, Acc: 0.6676923076923077, F1-Macro: 0.6420412825324304\n",
            "Early stopping counter 6/10\n",
            "Epoch 10, Train loss: 0.345531275206142, Acc: 0.8347676419965576, F1-Macro: 0.8342065312924472\n",
            "Epoch 10, Val loss: 0.7168979942798615, Acc: 0.7353846153846154, F1-Macro: 0.7348197343453511\n",
            "Validation acc increased 0.6984615384615385 -> 0.7353846153846154\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 37% 11/30 [1:05:11<1:54:34, 361.79s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 11, Train loss: 0.30446486324071886, Acc: 0.8643717728055077, F1-Macro: 0.8637829209820262\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 40% 12/30 [1:11:09<1:48:10, 360.56s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 11, Val loss: 0.7341024458408356, Acc: 0.68, F1-Macro: 0.679632999696694\n",
            "Early stopping counter 1/10\n",
            "Epoch 12, Train loss: 0.3109717833499114, Acc: 0.8605851979345955, F1-Macro: 0.8600832299786805\n",
            "Epoch 12, Val loss: 0.759900027513504, Acc: 0.7384615384615385, F1-Macro: 0.7370274824129691\n",
            "Validation acc increased 0.7353846153846154 -> 0.7384615384615385\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 43% 13/30 [1:17:20<1:43:03, 363.75s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 13, Train loss: 0.2843486757742034, Acc: 0.8767641996557659, F1-Macro: 0.8762839235122761\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 47% 14/30 [1:23:27<1:37:14, 364.67s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 13, Val loss: 0.7952217638492585, Acc: 0.6892307692307692, F1-Macro: 0.6892307692307692\n",
            "Early stopping counter 1/10\n",
            "Epoch 14, Train loss: 0.2822704336709446, Acc: 0.8753872633390706, F1-Macro: 0.8746352105288255\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 50% 15/30 [1:29:41<1:31:54, 367.61s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 14, Val loss: 0.7452893078327179, Acc: 0.6984615384615385, F1-Macro: 0.6842282677664975\n",
            "Early stopping counter 2/10\n",
            "Epoch 15, Train loss: 0.28119015933738817, Acc: 0.8791738382099827, F1-Macro: 0.8789005580891454\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 53% 16/30 [1:35:42<1:25:18, 365.63s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 15, Val loss: 0.917807611823082, Acc: 0.683076923076923, F1-Macro: 0.6765981702074216\n",
            "Early stopping counter 3/10\n",
            "Epoch 16, Train loss: 0.2510540613697635, Acc: 0.8860585197934595, F1-Macro: 0.8852754752324337\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 57% 17/30 [1:41:52<1:19:31, 367.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 16, Val loss: 1.0596267700195312, Acc: 0.6615384615384615, F1-Macro: 0.6606098579782791\n",
            "Early stopping counter 4/10\n",
            "Epoch 17, Train loss: 0.2512165416445997, Acc: 0.8833046471600688, F1-Macro: 0.8829223528018709\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 60% 18/30 [1:46:23<1:07:37, 338.17s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 17, Val loss: 0.6800710663199425, Acc: 0.7323076923076923, F1-Macro: 0.7273095506755779\n",
            "Early stopping counter 5/10\n",
            "Epoch 18, Train loss: 0.24100561357206768, Acc: 0.891566265060241, F1-Macro: 0.8911667855408549\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 63% 19/30 [1:50:29<56:56, 310.58s/it]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 18, Val loss: 0.7564676411449909, Acc: 0.6953846153846154, F1-Macro: 0.6891574645682983\n",
            "Early stopping counter 6/10\n",
            "Epoch 19, Train loss: 0.22181715758310425, Acc: 0.9029259896729777, F1-Macro: 0.9024012897359625\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 67% 20/30 [1:54:36<48:34, 291.45s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 19, Val loss: 0.8131729274988174, Acc: 0.7261538461538461, F1-Macro: 0.7215027777510326\n",
            "Early stopping counter 7/10\n",
            "Epoch 20, Train loss: 0.21635901224282053, Acc: 0.90223752151463, F1-Macro: 0.90177659801434\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 70% 21/30 [1:58:41<41:36, 277.36s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 20, Val loss: 0.7695200502872467, Acc: 0.72, F1-Macro: 0.7199045355103277\n",
            "Early stopping counter 8/10\n",
            "Epoch 21, Train loss: 0.21451051897472806, Acc: 0.9005163511187607, F1-Macro: 0.8998211434907937\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 73% 22/30 [2:02:50<35:52, 269.07s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 21, Val loss: 0.7000075556337834, Acc: 0.7138461538461538, F1-Macro: 0.7127583749109052\n",
            "Early stopping counter 9/10\n",
            "Epoch 22, Train loss: 0.2043658343454202, Acc: 0.9070567986230637, F1-Macro: 0.9067182817182817\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 73% 22/30 [2:06:55<46:09, 346.17s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 22, Val loss: 0.8204008877277374, Acc: 0.6953846153846154, F1-Macro: 0.6927667701121986\n",
            "Early stopping counter 10/10\n",
            "Early stopped\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "for epoch_index in tqdm(range(30)):\n",
        "\n",
        "    trainer.train_epoch(train_dataloader, epoch_index)\n",
        "    trainer.validate_epoch(validation_dataloader, epoch_index)\n",
        "    wandb.log({'train_loss' : trainer.train_mean_loss,\n",
        "               'validation_loss' : trainer.val_mean_loss,\n",
        "               'train_acc' : trainer.train_score,\n",
        "               'validation_acc' : trainer.validation_score})\n",
        "    # early_stopping check\n",
        "    early_stopper.check_early_stopping(acc = trainer.validation_score)\n",
        "\n",
        "    if early_stopper.stop:\n",
        "        print('Early stopped')\n",
        "        break\n",
        "\n",
        "    if early_stopper.save_model:\n",
        "        check_point = {\n",
        "            'model': model.state_dict(),\n",
        "            'optimizer': optimizer.state_dict(),\n",
        "            'scheduler': scheduler.state_dict()\n",
        "        }\n",
        "        torch.save(check_point, 'best.pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe53514a-e83f-4795-9589-640f26cc2993",
      "metadata": {
        "id": "fe53514a-e83f-4795-9589-640f26cc2993"
      },
      "source": [
        "## Inference\n",
        "### 모델 로드"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e189a73e-5168-44f4-9230-d942a4d888fd",
      "metadata": {
        "id": "e189a73e-5168-44f4-9230-d942a4d888fd",
        "outputId": "6f6669cf-3f97-40b6-eeb1-e7c4f787b0a1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<br/>Waiting for W&B process to finish, PID 24458... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
              "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_acc</td><td>▁▂▃▅▅▆▆▆▆▇▇▇▇█▇████████</td></tr><tr><td>train_loss</td><td>███▆▆▅▅▄▄▃▃▂▃▂▂▂▂▂▂▁▁▁▁</td></tr><tr><td>validation_acc</td><td>▁▂▅▇▆▇▄▅▆▆█▆█▆▇▆▆█▇█▇▇▇</td></tr><tr><td>validation_loss</td><td>▃▃▂▂█▁▂▃▅▅▂▃▃▄▃▆█▂▃▄▃▂▄</td></tr></table><br/></div><div class=\"wandb-col\">\n",
              "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_acc</td><td>0.90706</td></tr><tr><td>train_loss</td><td>0.20437</td></tr><tr><td>validation_acc</td><td>0.69538</td></tr><tr><td>validation_loss</td><td>0.8204</td></tr></table>\n",
              "</div></div>\n",
              "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
              "<br/>Synced <strong style=\"color:#cdcd00\">VGG16_vaild_aug_L2</strong>: <a href=\"https://wandb.ai/pnm-team/week1_Image/runs/jxbrkc0x\" target=\"_blank\">https://wandb.ai/pnm-team/week1_Image/runs/jxbrkc0x</a><br/>\n",
              "Find logs at: <code>./wandb/run-20220211_024211-jxbrkc0x/logs</code><br/>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6729cfde-c4b3-4d36-938e-f8bb8d8afef3",
      "metadata": {
        "id": "6729cfde-c4b3-4d36-938e-f8bb8d8afef3"
      },
      "outputs": [],
      "source": [
        "TRAINED_MODEL_PATH = 'best.pt'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "75bbba92-b53c-499f-b5f9-b6ac3edde331",
      "metadata": {
        "id": "75bbba92-b53c-499f-b5f9-b6ac3edde331"
      },
      "source": [
        "### Load dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ced90de9-50ec-4e18-9f42-5a1b493941a5",
      "metadata": {
        "id": "ced90de9-50ec-4e18-9f42-5a1b493941a5"
      },
      "outputs": [],
      "source": [
        "class TestDataset(Dataset):\n",
        "    def __init__(self, data_dir, input_shape):\n",
        "        self.data_dir = data_dir\n",
        "        self.input_shape = input_shape\n",
        "        \n",
        "        # Loading dataset\n",
        "        self.db = self.data_loader()\n",
        "        \n",
        "        # Transform function\n",
        "        self.transform = transforms.Compose([transforms.Resize(self.input_shape),\n",
        "                                             transforms.ToTensor(),\n",
        "                                             transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "\n",
        "    def data_loader(self):\n",
        "        print('Loading test dataset..')\n",
        "        if not os.path.isdir(self.data_dir):\n",
        "            print(f'!!! Cannot find {self.data_dir}... !!!')\n",
        "            sys.exit()\n",
        "        \n",
        "        db = pd.read_csv(os.path.join(self.data_dir, 'sample_submission.csv'))\n",
        "        return db\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.db)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        data = copy.deepcopy(self.db.loc[index])\n",
        "        \n",
        "        # Loading image\n",
        "        cvimg = cv2.imread(os.path.join(self.data_dir,'test',data['file_name']), cv2.IMREAD_COLOR | cv2.IMREAD_IGNORE_ORIENTATION)\n",
        "        if not isinstance(cvimg, np.ndarray):\n",
        "            raise IOError(\"Fail to read %s\" % data['file_name'])\n",
        "\n",
        "        # Preprocessing images\n",
        "        trans_image = self.transform(Image.fromarray(cvimg))\n",
        "\n",
        "        return trans_image, data['file_name']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cdd31a3d-08cd-48fc-87b0-137976d4d4bb",
      "metadata": {
        "id": "cdd31a3d-08cd-48fc-87b0-137976d4d4bb",
        "outputId": "dee2cb65-1795-43ec-be51-ffc3b1c55683"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading test dataset..\n"
          ]
        }
      ],
      "source": [
        "# Load dataset & dataloader\n",
        "test_dataset = TestDataset(data_dir=DATA_DIR, input_shape=INPUT_SHAPE)\n",
        "test_dataloader = DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "53efd72b-172d-4e34-a1dd-65ed8c745b58",
      "metadata": {
        "id": "53efd72b-172d-4e34-a1dd-65ed8c745b58"
      },
      "source": [
        "### 추론 진행"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "16a090ea-bb34-4d3d-a127-b1190e8c416c",
      "metadata": {
        "tags": [],
        "id": "16a090ea-bb34-4d3d-a127-b1190e8c416c",
        "outputId": "d9662752-5fe3-4b9e-92d8-004f192826df"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "1it [00:01,  1.57s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[9.9911e-01, 8.8869e-04],\n",
            "        [7.7043e-01, 2.2957e-01],\n",
            "        [2.3372e-01, 7.6628e-01],\n",
            "        [1.8680e-01, 8.1320e-01],\n",
            "        [9.9992e-01, 8.4431e-05],\n",
            "        [1.2321e-01, 8.7679e-01],\n",
            "        [2.0412e-01, 7.9588e-01],\n",
            "        [8.6829e-01, 1.3171e-01],\n",
            "        [9.9456e-01, 5.4374e-03],\n",
            "        [3.9663e-03, 9.9603e-01],\n",
            "        [9.9941e-01, 5.9012e-04],\n",
            "        [9.8077e-01, 1.9234e-02],\n",
            "        [9.9956e-01, 4.4463e-04],\n",
            "        [2.0804e-01, 7.9196e-01],\n",
            "        [9.8812e-01, 1.1876e-02],\n",
            "        [9.9869e-01, 1.3110e-03],\n",
            "        [9.9184e-01, 8.1572e-03],\n",
            "        [9.9851e-01, 1.4910e-03],\n",
            "        [9.9973e-01, 2.6939e-04],\n",
            "        [9.9813e-01, 1.8698e-03],\n",
            "        [9.9999e-01, 6.3140e-06],\n",
            "        [9.9655e-01, 3.4538e-03],\n",
            "        [9.3449e-01, 6.5507e-02],\n",
            "        [9.9996e-01, 4.3025e-05],\n",
            "        [1.3920e-01, 8.6080e-01],\n",
            "        [9.9990e-01, 1.0319e-04],\n",
            "        [9.9996e-01, 4.3913e-05],\n",
            "        [3.5414e-01, 6.4586e-01],\n",
            "        [4.1676e-03, 9.9583e-01],\n",
            "        [1.7577e-02, 9.8242e-01],\n",
            "        [8.9499e-01, 1.0501e-01],\n",
            "        [6.9160e-03, 9.9308e-01]], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2it [00:03,  1.76s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[1.9506e-02, 9.8049e-01],\n",
            "        [9.9989e-01, 1.1437e-04],\n",
            "        [9.9908e-01, 9.2365e-04],\n",
            "        [8.4223e-01, 1.5777e-01],\n",
            "        [9.6062e-01, 3.9378e-02],\n",
            "        [5.4982e-01, 4.5018e-01],\n",
            "        [1.1816e-02, 9.8818e-01],\n",
            "        [9.9157e-01, 8.4310e-03],\n",
            "        [6.1721e-01, 3.8279e-01],\n",
            "        [9.8184e-01, 1.8163e-02],\n",
            "        [9.8325e-01, 1.6747e-02],\n",
            "        [1.6275e-03, 9.9837e-01],\n",
            "        [6.6470e-01, 3.3530e-01],\n",
            "        [2.3743e-01, 7.6257e-01],\n",
            "        [2.4738e-01, 7.5262e-01],\n",
            "        [4.2999e-01, 5.7001e-01],\n",
            "        [1.1633e-01, 8.8367e-01],\n",
            "        [9.9149e-01, 8.5109e-03],\n",
            "        [5.8893e-01, 4.1107e-01],\n",
            "        [9.6802e-03, 9.9032e-01],\n",
            "        [9.2450e-02, 9.0755e-01],\n",
            "        [9.9375e-01, 6.2507e-03],\n",
            "        [9.0899e-01, 9.1008e-02],\n",
            "        [1.2821e-01, 8.7179e-01],\n",
            "        [8.9474e-01, 1.0526e-01],\n",
            "        [8.8319e-01, 1.1681e-01],\n",
            "        [2.8759e-01, 7.1241e-01],\n",
            "        [7.3660e-01, 2.6340e-01],\n",
            "        [7.1898e-03, 9.9281e-01],\n",
            "        [9.9993e-01, 6.7791e-05],\n",
            "        [9.7687e-01, 2.3134e-02],\n",
            "        [9.9814e-01, 1.8612e-03]], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "4it [00:05,  1.49s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[2.6554e-02, 9.7345e-01],\n",
            "        [7.7259e-04, 9.9923e-01],\n",
            "        [1.7740e-01, 8.2260e-01],\n",
            "        [4.9192e-02, 9.5081e-01],\n",
            "        [9.8544e-01, 1.4557e-02],\n",
            "        [9.9607e-01, 3.9339e-03],\n",
            "        [9.8066e-01, 1.9336e-02],\n",
            "        [7.2136e-01, 2.7864e-01],\n",
            "        [6.5082e-01, 3.4918e-01],\n",
            "        [9.9989e-01, 1.0801e-04],\n",
            "        [2.3926e-03, 9.9761e-01],\n",
            "        [3.7997e-01, 6.2003e-01],\n",
            "        [9.9971e-01, 2.8567e-04],\n",
            "        [9.9910e-01, 8.9819e-04],\n",
            "        [1.8224e-01, 8.1776e-01],\n",
            "        [9.5346e-03, 9.9047e-01],\n",
            "        [1.0586e-02, 9.8941e-01],\n",
            "        [9.8910e-01, 1.0904e-02],\n",
            "        [9.9669e-01, 3.3130e-03],\n",
            "        [2.6780e-02, 9.7322e-01],\n",
            "        [9.3147e-02, 9.0685e-01],\n",
            "        [1.4807e-01, 8.5193e-01],\n",
            "        [9.8782e-01, 1.2185e-02],\n",
            "        [9.3377e-01, 6.6226e-02],\n",
            "        [9.8774e-01, 1.2258e-02],\n",
            "        [8.9350e-01, 1.0650e-01],\n",
            "        [9.7992e-01, 2.0084e-02],\n",
            "        [9.8216e-01, 1.7844e-02],\n",
            "        [3.8387e-03, 9.9616e-01],\n",
            "        [1.7539e-01, 8.2461e-01],\n",
            "        [9.9530e-01, 4.7038e-03],\n",
            "        [9.9987e-01, 1.2775e-04]], device='cuda:0')\n",
            "tensor([[0.8170, 0.1830],\n",
            "        [0.0054, 0.9946],\n",
            "        [0.1468, 0.8532],\n",
            "        [0.1158, 0.8842]], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "model.load_state_dict(torch.load(TRAINED_MODEL_PATH)['model'])\n",
        "\n",
        "# Prediction\n",
        "file_lst = []\n",
        "pred_lst = []\n",
        "prob_lst = []\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for batch_index, (img, file_num) in tqdm(enumerate(test_dataloader)):\n",
        "        img = img.to(DEVICE)\n",
        "        pred = model(img)\n",
        "        print(pred)\n",
        "        file_lst.extend(list(file_num))\n",
        "        pred_lst.extend(pred.argmax(dim=1).tolist())\n",
        "        prob_lst.extend(pred[:, 1].tolist())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "056169d1-64a8-4b81-8daf-722b029cf2b9",
      "metadata": {
        "id": "056169d1-64a8-4b81-8daf-722b029cf2b9"
      },
      "source": [
        "### 결과 저장"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f133cd86-b87b-4f8b-ae0e-c240655ae9ff",
      "metadata": {
        "id": "f133cd86-b87b-4f8b-ae0e-c240655ae9ff"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame({'file_name':file_lst, 'COVID':pred_lst})\n",
        "# df.sort_values(by=['file_name'], inplace=True)\n",
        "df.to_csv('vgg16_2.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01a99abe-38f7-4f52-a6cf-b65c5a99aef7",
      "metadata": {
        "id": "01a99abe-38f7-4f52-a6cf-b65c5a99aef7"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "vggnet16-augmentation-withL2.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}